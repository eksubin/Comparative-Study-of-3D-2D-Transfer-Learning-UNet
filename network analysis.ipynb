{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "31541680-02d1-4dc8-b658-c351e416e010",
   "metadata": {},
   "source": [
    "### 3D unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b08304-89e1-44ea-a569-9c026230f99b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from monai.utils import first, set_determinism\n",
    "from monai.transforms import (\n",
    "    AsDiscrete,\n",
    "    AsDiscreted,\n",
    "    EnsureChannelFirstd,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    SaveImaged,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    Invertd,\n",
    "    Lambdad,\n",
    "    Activations,\n",
    "    ScaleIntensityRange,\n",
    "    Lambda,\n",
    "    Transposed\n",
    ")\n",
    "from monai.handlers.utils import from_engine\n",
    "from monai.networks.nets import UNet, UNETR\n",
    "from monai.networks.layers import Norm\n",
    "from monai.metrics import DiceMetric, compute_hausdorff_distance\n",
    "from monai.losses import DiceLoss\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.data import CacheDataset, DataLoader, Dataset, decollate_batch\n",
    "from monai.config import print_config\n",
    "from monai.apps import download_and_extract\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import tempfile\n",
    "import shutil\n",
    "import os\n",
    "import glob\n",
    "import nrrd\n",
    "from monai.losses import SSIMLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca9c9aa-5aa5-4d61-a120-eb347c22381d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def binarize(label, threshold=0.1):\n",
    "    binary_mask = (label > threshold)\n",
    "    binary_mask[binary_mask > 0] = 1  # Set all non-zero pixels to 1\n",
    "    return binary_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4016c9-4561-400d-800e-d6e4398fcd0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_type = 'unetTrans'\n",
    "val_interval = 2\n",
    "best_metric = -1\n",
    "best_metric_epoch = -1\n",
    "epoch_loss_values = []\n",
    "metric_values = []\n",
    "post_pred = Compose([AsDiscrete(argmax=True, to_onehot=2)])\n",
    "post_label = Compose([AsDiscrete(to_onehot=2)])\n",
    "\n",
    "directory = os.environ.get(\"DATA_DIRECTORY\")\n",
    "root_dir = \"./Test\"\n",
    "print(root_dir)\n",
    "\n",
    "train_images = sorted(\n",
    "    glob.glob(os.path.join(root_dir, \"RVolumes\", \"*.nrrd\")))\n",
    "train_labels = sorted(\n",
    "    glob.glob(os.path.join(root_dir, \"RLabels\", \"*.nrrd\")))\n",
    "val_files = [{\"image\": image_name, \"label\": label_name}\n",
    "            for image_name, label_name in zip(train_images, train_labels)]\n",
    "\n",
    "\n",
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"],\n",
    "                reader=\"NrrdReader\", image_only=True),\n",
    "        Transposed(keys=['image', 'label'], indices=[2, 1, 0]),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "        Lambdad((\"label\"), binarize),\n",
    "        #Lambdad((\"image\"),binarize),\n",
    "        ScaleIntensityRanged(\n",
    "            keys=[\"image\"],\n",
    "            a_min=-57,\n",
    "            a_max=1000,\n",
    "            b_min=0.0,\n",
    "            b_max=1.0,\n",
    "            clip=True,\n",
    "        ),\n",
    "        CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "    ]\n",
    ")\n",
    "val_ds = CacheDataset(\n",
    "    data=val_files, transform=val_transforms, cache_rate=1.0, num_workers=4)\n",
    "\n",
    "val_loader = DataLoader(val_ds, batch_size=1, num_workers=4)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n",
    "\n",
    "if model_type == 'unet' or model_type == 'unetTrans':\n",
    "    model = UNet(\n",
    "        spatial_dims=3,\n",
    "        in_channels=1,\n",
    "        out_channels=2,\n",
    "        channels=(16, 32, 64, 128, 256),\n",
    "        strides=(2, 2, 2, 2),\n",
    "        num_res_units=2,\n",
    "        norm=Norm.BATCH,\n",
    "    ).to(device)\n",
    "else:\n",
    "        model = UNETR(\n",
    "        in_channels=1,\n",
    "        out_channels=2,\n",
    "        img_size=(128, 128, 16),\n",
    "        feature_size=16,\n",
    "        hidden_size=768,\n",
    "        mlp_dim=3072,\n",
    "        num_heads=12,\n",
    "        pos_embed=\"perceptron\",\n",
    "        norm_name=\"instance\",\n",
    "        res_block=True,\n",
    "        dropout_rate=0.0,\n",
    "    ).to(device)\n",
    "loss_function = DiceLoss(to_onehot_y=True, softmax=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), 1e-4)\n",
    "\n",
    "if model_type == 'unet':\n",
    "    model.load_state_dict(torch.load(\"./NetworkOutput/best_metric_model1200.pth\"))\n",
    "elif model_type == 'unetTrans':\n",
    "    model.load_state_dict(torch.load(\n",
    "        \"/home/erattakulangara/hpchome/DeepLearningAlgo/2022_3D_Unet_segmentation/3D_Unet/ver_17.0_3D_Monai/NetworkOutput/Unet3DTrans/Models/Trans_OSIC_model_1500EP_5Layers_20Samples.pth\"))\n",
    "    print(\"Loaded Trans Unet\")\n",
    "else:\n",
    "    model.load_state_dict(torch.load(\"./UnetrOutput/best_metric_model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2750a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i, val_data in enumerate(val_loader):\n",
    "    loss = loss_function(val_data[\"image\"], val_data[\"label\"])\n",
    "    print(os.path.basename(train_images[i]),1-loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a17f12-c46c-4b93-8aa3-cebaba2487d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dice_metric = DiceMetric(include_background=True, reduction=\"none\")\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, val_data in enumerate(val_loader):\n",
    "        roi_size = (128, 128, 16)\n",
    "        sw_batch_size = 4\n",
    "        val_outputs = sliding_window_inference(\n",
    "            val_data[\"image\"].to(device), roi_size, sw_batch_size, model)\n",
    "        #dice_metric(y_pred=val_outputs[0][0], y=val_data[\"label\"][0][0].to(device))\n",
    "        #print('hausedorff ',compute_hausdorff_distance(y_pred=val_outputs[0][0].transpose(2,0,1), y=val_data[\"label\"][0][0].transpose(2,1,0).to(device)))\n",
    "        #loss = loss_function(val_outputs,val_data[\"label\"].to(device))\n",
    "        print(val_outputs.shape, val_data[\"label\"].shape)\n",
    "        #loss = 1-SSIMLoss(spatial_dims=2)(val_outputs[0,:1,:,:,:],val_data[\"label\"][0,:1,:,:,:].to(device))\n",
    "        #print(loss)\n",
    "        # print(dice_metric.aggregate())\n",
    "        # dice_metric.reset()\n",
    "        # plot the slice [:, :, 80]\n",
    "        plt.figure(\"check\", (18, 6))\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.title(f\"Volume {os.path.basename(train_images[i]).replace('.nrrd','')}\")\n",
    "        plt.imshow(val_data[\"image\"][0, 0, :, :, 15], cmap=\"gray\")\n",
    "\n",
    "        plt.subplot(1, 3, 2) \n",
    "        plt.title(f\"Label\")\n",
    "        plt.imshow(val_data[\"label\"][0, 0, :, :, 15])\n",
    "\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.title(f\"Output\")\n",
    "        plt.imshow(torch.argmax(\n",
    "            val_outputs, dim=1).detach().cpu()[0, :, :, 15])\n",
    "        print(torch.argmax(val_outputs,dim=1)[0].shape)\n",
    "\n",
    "        if model_type == 'unet':\n",
    "            out_path = \"./NetworkOutput/3DUnet/\"\n",
    "            #plt.savefig(os.path.join(\"./NetworkOutput/3DUnet/\", f\"modelOutput{i}.jpg\"))\n",
    "            #nrrd.write(os.path.join(out_path, os.path.basename(train_images[i])), torch.argmax(\n",
    "                #val_outputs, dim=1)[0].cpu().detach().numpy())\n",
    "        elif model_type == 'unetTrans':\n",
    "            out_path = \"./NetworkOutput/Unet3DTrans/Output/20-Samples/\"\n",
    "            plt.savefig(os.path.join(out_path, f\"modelOutput{i}.jpg\"))\n",
    "        else:\n",
    "            out_path = \"./NetworkOutput/UnetR/\"\n",
    "            #plt.savefig(os.path.join(\"./NetworkOutput/UnetR/\", f\"modelOutput{i}.jpg\"))\n",
    "            #nrrd.write(os.path.join(out_path, os.path.basename(train_images[i])), torch.argmax(\n",
    "            #    val_outputs, dim=1)[0].cpu().detach().numpy())\n",
    "        plt.show()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b1f7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.max(val_data[\"label\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1311ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for i, val_data in enumerate(val_loader):\n",
    "        print(val_data[\"image\"].shape)\n",
    "        plt.imshow(val_data[\"label\"][0][0][:,:,10])\n",
    "        break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cd392bbe-1f75-4d21-b42e-a16beafceb68",
   "metadata": {},
   "source": [
    "### Save image overlays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a390788-3daf-4bf0-a547-5eebe47c7a86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nrrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e01c00d-67cd-415f-b853-f71cfe9f194c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "volumep = \"./Test/2D-Unet/\"\n",
    "labelp = \"./Test/RLabels/\"\n",
    "volumes = sorted(\n",
    "    glob.glob(os.path.join(volumep, \"*.nrrd\")))\n",
    "labels = sorted(\n",
    "    glob.glob(os.path.join(labelp, \"*.nrrd\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23548b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.metrics import DiceMetric, compute_hausdorff_distance\n",
    "loss_function = DiceLoss(to_onehot_y=True, softmax=True)\n",
    "def one_hot_encode(array):\n",
    "    print(array.shape)\n",
    "    print(np.eye(2)[array].shape)#.transpose(3,0, 1, 2)[None].shape)\n",
    "    return np.eye(2)[array].astype(dtype=int).transpose(3, 0, 1, 2)[None]\n",
    "\n",
    "\n",
    "\n",
    "for i,sample in enumerate(volumes):\n",
    "    volume_data, volume_header = nrrd.read(sample)\n",
    "    mask_data, mask_header = nrrd.read(labels[i])\n",
    "    v = volume_data#.transpose(2,0,1)\n",
    "    m = mask_data.transpose(0,2,1)\n",
    "    #v = torch.from_numpy(v[4:36, :, :])\n",
    "    v = torch.from_numpy(v[:,:,:])\n",
    "    m = torch.from_numpy(m[:, :, :])\n",
    "    print(\"v\", v.shape, \"m\", m.shape)\n",
    "    loss = compute_hausdorff_distance(one_hot_encode(v), one_hot_encode(\n",
    "        m), include_background=False, distance_metric='euclidean')\n",
    "    print(os.path.basename(volumes[i]), loss)\n",
    "    #plt.axis('off')\n",
    "    #plt.imshow(v[15, :, :], cmap='gray')  # I would add interpolation='none'\n",
    "    #plt.imshow(m[12, :, :], cmap='jet', alpha=0.4*(m[12, :, :] > 0))\n",
    "    # plt.savefig(os.path.join(\"./Figures/Volume/\", os.path.basename(sample) +\n",
    "    #             \".png\"), bbox_inches='tight', pad_inches=0)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36a8ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.moveaxis(volume_data, 0, -1)\n",
    "v = np.moveaxis(volume_data, -1, 1)\n",
    "m = np.moveaxis(mask_data, 0, -1)\n",
    "m = np.moveaxis(mask_data, -1, 1)\n",
    "plt.imshow(v[10,:,:], cmap='gray') # I would add interpolation='none'\n",
    "plt.imshow(m[6,:,:], cmap='jet', alpha=0.4*(m[6,:,:]>0)   )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8fae6d0e",
   "metadata": {},
   "source": [
    "### single image overlays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90ee644",
   "metadata": {},
   "outputs": [],
   "source": [
    "volume = \"Test/RVolumes/9.nrrd\"\n",
    "label = \"./NetworkOutput/3DUnet/9.nrrd\"\n",
    "volume_data, volume_header = nrrd.read(volume)\n",
    "mask_data, mask_header = nrrd.read(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6056df0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = volume_data.transpose(0,2,1)\n",
    "m = mask_data.transpose(2,0,1)\n",
    "print(\"v\", v.shape, \"m\", m.shape)\n",
    "plt.imshow(v[10,:,:], cmap='gray') # I would add interpolation='none'\n",
    "plt.imshow(m[10,:,:], cmap='jet',alpha=0.8*(m[10,:,:]>0.1)   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091d104e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nrrd\n",
    "filename_vds_osa = ['./results_espirit_9_2espiritarms_5latVec800frms_10_Geph39_feph_sl10.npy']\n",
    "filename_vds_osa_sl08 = ['sl10.nrrd']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df211569",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,files in enumerate(filename_vds_osa):\n",
    "    data_vds_osa = np.abs(np.load(files))\n",
    "    print(data_vds_osa.shape)\n",
    "    nrrd.write(filename_vds_osa_sl08[i], data_vds_osa)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
